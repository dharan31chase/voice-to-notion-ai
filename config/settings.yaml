# AI Assistant Configuration
# Main application settings

# OpenAI API Configuration
openai:
  model: "gpt-3.5-turbo"
  max_tokens:
    title_generation: 50
    task_analysis: 500
    note_analysis: 800
    project_detection: 100
    duration_estimation: 200
  temperature: 0.7
  retry_attempts: 3
  retry_delay_seconds: 2

# File Paths (relative to project root)
paths:
  transcripts: "transcripts/"
  processed: "processed/"
  archives: "Recording Archives/"
  failed: "Failed/"
  cache: ".cache/"
  config: "config/"
  staging: "staging/"  # Phase 1: Local staging for USB files before transcription
  usb_recorder: "/Volumes/IC RECORDER/REC_FILE/FOLDER01"

# Notion Integration
# Note: Database IDs come from environment variables
notion:
  chunk_size: 2000  # Characters per block
  retry_attempts: 3
  retry_delay_seconds: 2

# Feature Flags
features:
  enable_icon_matching: true
  enable_duplicate_detection: true
  enable_project_cache: true
  cache_duration_minutes: 60

# Processing Settings
processing:
  min_transcript_length: 10  # Characters
  min_file_size: 10  # Bytes
  parallel_transcription_workers: 3  # Reduced from 4 for better CPU utilization (Phase 1 optimization)
  cpu_usage_limit_percent: 70  # Increased from 50 to reduce throttling cycles (Phase 1 optimization)

  # Phase 1 Performance Optimizations
  staging_enabled: true  # Copy files to local SSD before transcription (eliminates USB I/O bottleneck)
  batch_work_budget_minutes: 7  # Target audio duration per batch for balanced processing
  batch_min_files: 1  # Allow single long file in a batch
  batch_max_files: 4  # Maximum files per batch to prevent oversized batches
  skip_short_audio_seconds: 2  # Auto-skip audio files shorter than this (likely recording errors)
  retry_on_permission_errors: false  # Don't retry USB permission errors (Phase 1: use staging instead)
  retry_on_short_transcript_errors: false  # Don't retry "transcript too short" errors

# Whisper Transcription Settings
whisper:
  model: "turbo"  # Options: tiny, base, small, medium, large, large-v2, large-v3, turbo
  language: "en"     # Language code (en, es, fr, etc.)
  output_format: "txt"  # Output format
  # Model comparison:
  # - tiny/base/small: Fast but less accurate
  # - medium: Balanced speed and accuracy
  # - large/large-v2/large-v3: Best accuracy, slower (~4x real-time)
  # - turbo: Newest, optimized for speed with good accuracy (RECOMMENDED)

# Archive Settings
archive:
  retention_days: 7
  organize_by_date: true
  session_id_format: "session_%Y%m%d_%H%M%S"

# Logging
logging:
  level: "INFO"  # DEBUG, INFO, WARNING, ERROR
  format: "%(asctime)s - %(levelname)s - %(message)s"
  file: "recording_orchestrator.log"
  console_output: true


